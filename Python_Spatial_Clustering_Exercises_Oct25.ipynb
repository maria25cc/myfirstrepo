{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22251e58-78c4-44bf-b39e-a3e7619120ee",
      "metadata": {
        "id": "22251e58-78c4-44bf-b39e-a3e7619120ee"
      },
      "source": [
        "# Python for Spatial Analysis\n",
        "### Second part of the module of GG3209 Spatial Analysis with GIS\n",
        "---\n",
        "# Notebook to practice Spatial Clustering - Exercises\n",
        "---\n",
        "Dr Fernando Benitez -  University of St Andrews - School of Geography and Sustainable Development"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get the required data in your Drive\n",
        "\n",
        "Go to [Kaggle - Car Accidents in the UK](https://www.kaggle.com/datasets/devansodariya/road-accident-united-kingdom-uk-dataset/) and download the **Road Accident (United Kingdom (UK)) dataset**. This dataset included **more than a millon of observations. So you definitly need to slide it to be able to work on Colab. This will be one of the challenges you will face.**\n",
        "\n",
        "Upload the dataset in your **Google Drive**, Make sure you mount the Drive (if you don't recall how to do that, check the guideline about GeoPandas) in this Notebook so you can access the data in the following tasks.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6KMcgqNOQuz9"
      },
      "id": "6KMcgqNOQuz9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory Data Analysis and K-means Clustering\n",
        "\n",
        "Install additional libraries like Lonboard to display large datasets.\n",
        "\n",
        "## Part A: Data Exploration and Pre-Processing\n",
        "\n",
        "1. Use pandas to load the car accidents dataset.\n",
        "2. Display the first few rows to understand the available attributes.\n",
        "3. Keep only the necessary columns, have a mix of Numerical and Categorical attributes\n",
        "4. Slice (cut) the pandas dataframe by including only records from 2010, which will reduce your dataset to approx 770585 rows.\n",
        "5. Make a simple plot to represent which day of the week historically has had more car accidents. Which day?\n",
        "6. Make a second plot to explore the relationship between **Accident Severity** and **Road Conditions**. What insights can you gain about that?. Use a Text Cell reflecting on the previous charts.\n",
        "7. Using Lonboard Library map all the car accidents included in the filtered dataset.\n",
        "8. Make a spatial filter (create a new dataset) to map only the car accidents In the Glasgow-Edinburgh Region, create another map using the lonboard library to display the car accidents only in that region.\n",
        "\n",
        "## Part B: K-means Clustering Implementation:\n",
        "\n",
        "1. Implement K-means clustering with different values of k. (e.g 3 and 5 clusters) To the filtered dataset you have created for the Glasgow-Edinburgh region.\n",
        "2. Map the clusters using the lonboard library.\n",
        "3. Describe in a Text Cell the clustering results. **How does the choice of k impact the clusters?**. Describe how the clusters change once you adjust multiple versions of that required parameter.\n",
        "4. **Finally**: In the guideline, we worked using only the coordinates to create the clusters (`['Longitude', 'Latitude'`]), in another code cell, implement K-means clustering again, but now using the attributes included in the dataframe like `Accident_Severity, Number_of_Vehicles`.\n",
        "5. Visualise the results using the `lonboard` library.\n",
        "6. In a Text Cell, reflect on the clusters that include only the coordinates and the ones that also include other attributes. What insights can you gain about that?\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "C3bFJhbnoX61"
      },
      "id": "C3bFJhbnoX61"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Spatial Analysis and DBSCAN Clustering\n",
        "\n",
        "## Part A: Spatial Correlation\n",
        "\n",
        "1. Create another GeoPandas Dataframe by rereading the data to avoid any confusion with the previous geodataframe. This new one is about DBSCAN name it accordingly.\n",
        "\n",
        "2. Using the [BBox website](https://boundingbox.klokantech.com/), filter the\n",
        "new geodataframe to contain only the accidents around **Birmingham**.\n",
        "\n",
        "3. Using the Lonboard library, map the filtered dataset in **Birmingham**.\n",
        "\n",
        "Before creating any spatial clustering, **it would be beneficial to explore any correlations to identify potential relationships between variables**, such as whether bad weather conditions influence accident severity or whether the number of vehicles involved correlates with the number of casualties.\n",
        "\n",
        "4. In a code cell, investigate the data type of the attribute list, so you can identify which attributes are numerical and which are categorical. Tip: use `.dtypes`\n",
        "\n",
        "5. In a code cell. Run the correlation between the numerical attributes by including in your code `corr= your_dataframe.corr()`\n",
        "\n",
        "**You probably got an error running the previous code.**\n",
        "**How can you solve this issue?**\n",
        "\n",
        "Before asking ChatGPT or any GenAI tool, try **Pandas documentation** and see the parameters of the **corr** function, and find which is the parameter you need to only create a correlation matrix only for the numerical attributes. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html\n"
      ],
      "metadata": {
        "id": "S_GH8fITqj0w"
      },
      "id": "S_GH8fITqj0w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. In a new Code Cell. Adjust the following code to create a heatmap plot of your correlation values."
      ],
      "metadata": {
        "id": "guJCmhrjJ549"
      },
      "id": "guJCmhrjJ549"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    your_corr_variable,\n",
        "    annot=True,\n",
        "    cmap='coolwarm',\n",
        "    fmt='.2f',           # Format annotations to 2 decimal places\n",
        "    linewidths=0.5,\n",
        "    cbar_kws={'label': 'Correlation Coefficient'}\n",
        ")\n",
        "\n",
        "plt.title('Pearson -Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ofQaSaF6Jbqe"
      },
      "id": "ofQaSaF6Jbqe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In terms of predictive modelling, having strong correlations indicate that one variable is an excellent predictor of the other. For example, if `Number_of_Casualties` has a 0.99 correlation (Pearson) with a separate column called `Injured_People_Count`, you know they convey almost identical information.\n",
        "\n",
        "But **therer are downsides like potential Multicollinearity**, which means, if you are building a predictive model (like linear regression), having two variables that are too highly correlated (often > 0.9) can cause multicollinearity and require you to remove one of them.\n",
        "\n",
        "Here is where our module associated with **Spatial Data Science** plays an important role. **Spatial statistical models** differ from standard (non-spatial) statistical models because they explicitly account for geographic location and the principle that nearby things are more related than distant things. The first law of geography.\n",
        "\n",
        "In the same way you have evaluated and learn from the GWR method, in this exercise, we can apply Moran's I.\n",
        "\n",
        "In this context of our car accident dataset, while a standard stadistic(Pearson) might tell you that severe weather correlates globally with severe accidents, a spatial model could tell us that this relationship only holds true in coastal areas, while in mountain areas, road surface conditions are more important locally.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "f4OHhZqRJOXv"
      },
      "id": "f4OHhZqRJOXv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Install the library **pysal** by running in a code cell:\n",
        "`pip install pysal `\n",
        "\n",
        "8. Now import the new and requieres libraries.\n",
        "\n",
        "```\n",
        "import libpysal.weights as weights\n",
        "from esda.moran import Moran\n",
        "```\n",
        "9. You must reproject your dataset (recall the EPSG code you used in the guideline notebook to study spatial data in the UK)\n",
        "\n"
      ],
      "metadata": {
        "id": "t-2VKulRyqvj"
      },
      "id": "t-2VKulRyqvj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you reproject the dataset, you can now use it to run Local Moran's I and Spatial clustering DBSCAN. **Adjust the following code to match your variable and datasets**"
      ],
      "metadata": {
        "id": "THnAp30mD3ho"
      },
      "id": "THnAp30mD3ho"
    },
    {
      "cell_type": "code",
      "source": [
        "w = weights.DistanceBand.from_dataframe(your_dataset_projected, threshold=500, ids=your_dataset.index) #Adjust this line to match your variables.\n",
        "w.transform = 'R'\n",
        "moran = Moran(your_dataset['Accident_Severity'], w) #Adjust this line to match your variables.\n",
        "\n",
        "print(f\"\\n--- Moran's I Spatial Autocorrelation Analysis ---\")\n",
        "print(f\"Defined {w.n} observations and {w.mean_neighbors:.2f} average neighbors per point.\")\n",
        "print(f\"\\nMoran's I Statistic (Observed I): {moran.I:.4f}\")\n",
        "print(f\"P-value (significance): {moran.p_sim:.4f}\")"
      ],
      "metadata": {
        "id": "ha61IlFBD20L"
      },
      "id": "ha61IlFBD20L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to read the results:**\n",
        "\n",
        "The resulting moran.I value tells you about the spatial pattern defined in the requested dataset.\n",
        "\n",
        "- **Near +1**: High positive spatial autocorrelation\n",
        "- **Near -1**: Negative spatial autocorrelation\n",
        "- **Near 0**: A random spatial pattern"
      ],
      "metadata": {
        "id": "xdHqCfN6FtCh"
      },
      "id": "xdHqCfN6FtCh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. In a Text Cell, describe with your own words the results., What insights can you gain from the correlation analysis."
      ],
      "metadata": {
        "id": "aitwxkyGGMtZ"
      },
      "id": "aitwxkyGGMtZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part B: DBSCAN Clustering Implementation:\n",
        "\n",
        "1. Implement DBSCAN clustering with different **eps** and **min_samples** to the projected dataset.\n",
        "2. Map the clusters using the Plotly Library.\n",
        "3. Describe in a Text Cell the clustering results. **How does the choice of eps and min_samples impact the clusters?**. Describe how the clusters change once you adjust multiple versions of that required parameter.\n",
        "4. In a Text Cell, briefly reflect on the clusters created using **K-Means** and the ones generated with **DBSCAN**. What insights can you gain from that?, Do you see any limitations?\n",
        "5. Finally, in a new text cell address the following question: **What do you think are the real-world implications of the identified clusters in the field of urban planning?**\n",
        "\n",
        "---\n",
        "\n",
        "If you finished the initial guide and all the challenges included in this notebeook. **Upload the finished version of both notebooks to your GitHub repository** (check how to do it in the workbook lab document included in Moodle), and **Congrats you have finished**\n",
        "\n",
        "### **Important Note:** Avoid using ChatGPT for your reflective notes. Instead, describe in your own words what you observe from your analysis results. I want to see and read your authentic thoughts and insights based on your understanding, rather than a complicated or overly structured response. Take some time to evaluate the results you have obtained and make an effort to briefly describe what you have found.\n"
      ],
      "metadata": {
        "id": "AkmP8ZC_KdTp"
      },
      "id": "AkmP8ZC_KdTp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "3f407111c129f019f2340fe5f9de2048ab167daf9d5431fe44f2b7f9a5a6e947"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}